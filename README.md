# ğŸ•‰ï¸ Krishna AI Content Analyzer

A production-ready **Hinglish content moderation and devotional tagging system** using state-of-the-art NLP and speech recognition.

## ğŸ¯ Features

### 1. **Speech-to-Text (ASR)**
- **Whisper (openai/whisper-small)** for multilingual transcription
- Automatic Devanagari â†’ Latin transliteration
- Optimized for Hinglish (Hindi + English code-switching)

### 2. **Multi-Task NLP Classification**
Single XLM-RoBERTa transformer with 3 specialized heads:

#### **Sentiment Analysis**
- Classes: Positive, Neutral, Negative
- Confidence scores for each prediction

#### **Toxicity Detection**
- Classes: Safe, Offensive/Hate Speech, Spam/Promotion
- Policy-based content moderation

#### **Devotional Category Tagging** (Multi-label)
- Career
- Love Life
- Family Issues
- Health Issues
- Mood Issues

## ğŸ—ï¸ Architecture

```
User Voice Input
   â†“
Whisper ASR (Backend)
   â†“
Text Normalization + Transliteration
   â†“
XLM-RoBERTa Multi-Task Model
   â”œâ”€â”€ Sentiment Head
   â”œâ”€â”€ Toxicity Head
   â””â”€â”€ Category Head
   â†“
Probabilistic Outputs + Confidence Scores
   â†“
UI Display
```

**Key Design Principles:**
- âœ… Single model, single forward pass
- âœ… Pure probabilistic inference (no keywords/rules)
- âœ… Class-weighted loss for imbalanced data
- âœ… Multi-label category classification

## ğŸš€ Quick Start

### Prerequisites
- Python 3.9+
- Node.js 16+
- 8GB+ RAM

### Backend Setup

```bash
cd backend

# Create virtual environment
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Generate training data (5,000 samples)
python generate_data.py

# Train the model (optional - pre-trained checkpoint included)
python train.py

# Start backend server
python app.py
```

Backend runs on: **http://localhost:50010**

### Frontend Setup

```bash
cd frontend

# Install dependencies
npm install

# Start development server
npm start
```

Frontend runs on: **http://localhost:3000**

## ğŸ“Š Model Training

### Dataset
- **5,000 synthetic Hinglish samples**
- Distribution:
  - Sentiment: 45% negative, 30% neutral, 25% positive
  - Toxicity: 85% safe, 10% offensive, 5% spam
  - Categories: Multi-label with mood_issues dominant

### Training Configuration
```python
Optimizer: AdamW
Learning Rate: 2e-5
Batch Size: 16
Epochs: 5
Encoder: Frozen for 1 epoch, then unfrozen
Loss: sentiment_loss + toxicity_loss + 0.8 * category_loss
```

### Performance
- **Final Validation Loss: 1.25**
- **Sentiment Accuracy: ~85%**
- **Toxicity Precision: ~90%**
- **Category F1: ~80%**

## ğŸ§ª Testing

### API Testing

```bash
# Test sentiment
curl -X POST http://localhost:50010/analyze \
  -H "Content-Type: application/json" \
  -d '{"text": "Me thik hu"}'

# Expected: Positive sentiment, Safe toxicity

# Test toxicity
curl -X POST http://localhost:50010/analyze \
  -H "Content-Type: application/json" \
  -d '{"text": "I want to kill somebody"}'

# Expected: Negative sentiment, Offensive toxicity

# Test neutral
curl -X POST http://localhost:50010/analyze \
  -H "Content-Type: application/json" \
  -d '{"text": "Kuch khaas nahi"}'

# Expected: Neutral sentiment, Safe toxicity
```

### Test Endpoint
```bash
curl http://localhost:50010/test
```

Returns predictions on 5 sample Hinglish queries.

## ğŸ“ Project Structure

```
krishna-ai-dashboard/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py                 # Flask API + Whisper integration
â”‚   â”œâ”€â”€ multitask_model.py     # Multi-task transformer model
â”‚   â”œâ”€â”€ train.py               # Training script
â”‚   â”œâ”€â”€ generate_data.py       # Synthetic data generator
â”‚   â”œâ”€â”€ requirements.txt       # Python dependencies
â”‚   â”œâ”€â”€ .env.example          # Environment variables template
â”‚   â””â”€â”€ checkpoints/          # Model weights (not in Git)
â”‚       â””â”€â”€ model.pt
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â””â”€â”€ App.jsx           # React UI
â”‚   â”œâ”€â”€ public/
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

## ğŸ”§ API Reference

### POST `/analyze`

**Request (Audio):**
```bash
curl -X POST http://localhost:50010/analyze \
  -F "audio=@recording.wav"
```

**Request (Text):**
```json
{
  "text": "Hinglish text here"
}
```

**Response:**
```json
{
  "success": true,
  "transcription": "Me thik hu",
  "data": {
    "sentiment": {
      "label": "positive",
      "confidence": 0.993
    },
    "toxicity": {
      "label": "safe",
      "confidence": 0.998
    },
    "categories": [
      {
        "label": "mood_issues",
        "confidence": 0.726
      }
    ]
  }
}
```

### GET `/health`
Health check endpoint.

### GET `/test`
Run test suite on sample queries.

## ğŸ“ Technical Details

### Why XLM-RoBERTa?
- Multilingual support (100+ languages)
- Strong performance on code-switched text
- Pretrained on large-scale multilingual corpus
- Efficient for production deployment

### Why Multi-Task Learning?
- Shared encoder learns better representations
- Single forward pass (faster inference)
- Regularization effect improves generalization
- Efficient resource utilization

### Transliteration Pipeline
```python
Whisper Output (Devanagari) â†’ Indic Transliteration â†’ Latin Script
"à¤®à¥ˆà¤‚ à¤ à¥€à¤• à¤¹à¥‚à¤‚" â†’ "main thik hun"
```

## ğŸš¨ Moderation Policy

| Condition | Action |
|-----------|--------|
| Toxicity > 85% | Block Krishna response |
| Spam > 75% | Rate limit user |
| Safe | Allow normal flow |

## ğŸ“ˆ Future Improvements

- [ ] Increase training data to 10K+ samples
- [ ] Add temperature scaling for calibration
- [ ] Implement GPU support for faster training
- [ ] Add more devotional categories
- [ ] Deploy on cloud (AWS/GCP)
- [ ] Add user feedback loop for continuous learning

## ğŸ¤ Contributing

This is an internship project demonstrating:
- Multi-task transformer architecture
- Production ML pipeline
- Full-stack integration (React + Flask)
- Speech recognition + NLP

## ğŸ“„ License

MIT License - See LICENSE file for details

## ğŸ‘¤ Author

**Ved** - AI/ML Internship Project

## ğŸ™ Acknowledgments

- OpenAI Whisper for ASR
- Hugging Face Transformers
- XLM-RoBERTa pretrained model
- React + Flask communities

---

**Built with â¤ï¸ for Krishna AI**
